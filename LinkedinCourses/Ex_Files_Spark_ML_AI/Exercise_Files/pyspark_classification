import o
import os
os.sytem('ls')
os.system('ls')
os.system('pwd')
from pyspark.sql.functions import *
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.feature import StringIndexer
iris_df = spark.read.csv('iris.data', inferSchema=True)
iris_df.take(3)
iris.show(3)
iris_df.show(3)
iris_df.show(10)
iris_df = iris_df.select(col('_c0')
iris_df = iris_df.select(
col('_c0').alias('sepal_length'),
col('_c1').alias('sepal_width'),
col('_c2').alias('petal_length'),
col('_c3').alias('petal_width'),
col('_c4').alias('species')
)
iris_df.show(3)
vectorassembler = VectorAssembler(inputCols=['sepal_length', 'sepal_width', 
'petal_length', 'petal_width'], 
outputCol='features')
vector_iris_df = vectorassembler.transform(iris_df)
vector_iris_df.show(3)
indexer = StringIndexer(inputCol='species', 
outputCol='label')
indexer_iris_df = indexer.fit(vector_iris_df).transform(vector_iris_df)
indexer_iris_df.show(3)
vector_iris_df
vector_iris_df.show()
indexer_iris_df.show(3)
vector_iris_df.show(3)
indexer_iris_df.show(5)
from pyspark.ml.classification import NaiveBayes
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
splits = indexer_iris_df.randomSplit([0.6, 0.4], 123)
type(splits)
dir(list)
dir(splits)
splits[0][0]
splits[0][0:]
splits[0][0:1]
splits[0]
splits[1]
splits[0].show(3)
splits[1].show(3)
train_df = splits[0]
test_df = splits[1]
indexer_iris_df.count()
train_df.count()
test_df.count()
nb = NaiveBayes(modelType='multinomial')
nbmodel = nb.fit(train_df)
predictions_df = nbmodel.transform(test_df)
predictions_df.show(3)
evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')
nbaccuracy = evaluator.evaluate(predictions_df)
nbaccuracy
indexer_iris_df.show(3)
indexer_iris_Df.count()
indexer_iris_df.count()
train_df.count()
test_df.count()
from pyspark.ml.classification import MultilayerPerceptronClassifier
layers = [4, 5, 5, 3]
mlp = MultilayerPerceptronClassifier(layers=layers, seed=123)
mlp_model = mlp.fit(train_df)
mlp_predictions = mlp_model.transform(test_df)
mlp_evaluator = MulticlassClassificationEvaluator(metricName='accuracy')
mlp_accuracy = mlp_evaluator.evaluate(mlp_predictions)
mlp_accuracy
mlp_predictions.show(3)
from pyspark.ml.classification import DecisionTreeClassifier
dt = DecisionTreeClassifier(labelCol='label', featuresCol='features')
dt_model = dt.fit(train_df)
dt_predictions = dt_model.transform(test_df)
dt_evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')
dt_accuracy = dt_evaluator.evaluate(dt_predictions)
dt_accuracy
import readline
readline.write_history_file('pyspark_classification')
